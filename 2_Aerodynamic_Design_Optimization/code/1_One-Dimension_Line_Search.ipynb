{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimension Line Search 一维线搜索\n",
    "\n",
    "## 问题描述\n",
    "\n",
    "Consider a rectangular wing of span $b$ and chord $c$. Its planform area is thus $ S=b c $ and its aspect ratio is $ A = b^{2} / S $. The drag of this wing can be approximated as,\n",
    "$$\n",
    "C_{D}=k C_{f} \\frac{S_{w e t}}{S}+\\frac{C_{L}^{2}}{\\pi A e}\n",
    "$$\n",
    "The first term corresponds to the parasite drag. $ C_{f} $ is the skin friction coefficient, which for a fully turbulent boundary layer can be approximated as,\n",
    "$$\n",
    "C_{f}=\\frac{0.074}{R e^{0.2}}\n",
    "$$\n",
    "Here, the Reynolds number $ (R e=\\rho V c / \\mu) $ is based on the wing chord. $ k $ is the form factor, which accounts for the effects of pressure drag.\n",
    "\n",
    "The second term in Equation (1) is the induced drag, where $ e $ is the Oswald efficiency factor. The lift coefficient $ C_{L} $ and the wing planform area $ S $ are to be kept constant. The values for all the constants are listed in Table 1. \n",
    "1. Write the total drag coefficient as a function of $ A $.\n",
    "2. Minimize $ C_{D} $ with respect to $ A $ using:   \n",
    "    (a) The golden section method  \n",
    "    (b) A line search method that satisfies sufficient decrease. (Bonus: A line search that satisfies the strong Wolfe conditions.)  \n",
    "    Converge the solutions to 6 significant digits.  \n",
    "3. Discuss the relative performance of these two methods. Try different starting points/intervals and compare convergence rates, number of iterations and any other metrics you find suitable.\n",
    "\n",
    "\\begin{array}{lrll}\n",
    "\\text { Quantity } & \\text { Value } & \\text { Units } & \\text { Description } \\\\\n",
    "\\hline \\rho & 1.23 & \\mathrm{~kg} / \\mathrm{m}^{3} & \\text { density of air } \\\\\n",
    "\\mu & 17.8 \\times 10^{-6} & \\mathrm{~kg} /(\\mathrm{m} \\mathrm{sec}) & \\text { viscosity of air } \\\\\n",
    "V & 35 & \\mathrm{~m} / \\mathrm{s} & \\text { airspeed } \\\\\n",
    "S & 11.8 & \\mathrm{~m}^{2} & \\text { planform area } \\\\\n",
    "S_{\\text {wet }} & 2.05 S & \\mathrm{~m}^{2} & \\text { wing wetted area } \\\\\n",
    "k & 1.2 & & \\text { form factor } \\\\\n",
    "C_{L} & 0.3 & & \\text { lift coefficient } \\\\\n",
    "e & 0.96 & & \\text { Oswald efficiency factor } \\\\\n",
    "\\hline\n",
    "\\end{array}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Cal_Re(c, rho=1.23, V=35.0, mu=17.8e-6):\n",
    "    \"\"\"Calculate Reynolds number.\"\"\"\n",
    "    return rho*V*c/mu\n",
    "\n",
    "def Cal_Cf(Re):\n",
    "    \"\"\"Calculate the skin friction coefficient\"\"\"\n",
    "    return 0.074/(Re**0.2)\n",
    "\n",
    "def Cal_Cd(A, k=1.2, S=11.8, S_ratio=2.05, Cl=0.3, e=0.96):\n",
    "    \"\"\"Calculate the total drag coefficient as the function of A\"\"\"\n",
    "    b = np.sqrt(A*S)\n",
    "    c = S/b\n",
    "    Re = Cal_Re(c)\n",
    "    Cf = Cal_Cf(Re)\n",
    "    return k*Cf*S_ratio+Cl**2/(np.pi*A*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Golden Section Method 黄金切割法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 36\n",
      "Iteration = 31\n",
      "9.999998507703083 0.012452367964004061\n",
      "Iteration = 33\n",
      "19.999998796784872 0.011639856490705125\n",
      "Iteration = 34\n",
      "28.394248943020834 0.011560688987166723\n",
      "Iteration = 33\n",
      "28.39424728323062 0.011560688987166721\n",
      "Iteration = 34\n",
      "28.3942482150752 0.011560688987166721\n",
      "Iteration = 35\n",
      "28.394248650832544 0.011560688987166723\n",
      "Iteration = 36\n",
      "28.39424726269298 0.011560688987166721\n",
      "Iteration = 33\n",
      "28.39424688677658 0.011560688987166723\n",
      "Iteration = 35\n",
      "28.394248642062152 0.01156068898716672\n",
      "Iteration = 36\n",
      "28.394248367400227 0.011560688987166718\n"
     ]
    }
   ],
   "source": [
    "class GoldenSectionMethod():\n",
    "    \"\"\"Golden Section Method\"\"\"\n",
    "    def __init__(self, function, x_min=1.0, x_max=100.0, tau=0.618, error = 1e-6):\n",
    "        self.x_max = x_max\n",
    "        self.x_min = x_min\n",
    "        self.function = function\n",
    "        self.tau = tau\n",
    "        self.error = error\n",
    "        self.recordmn = []\n",
    "        self.recordmin = []\n",
    "        self.recordfx = []\n",
    "\n",
    "    def Search(self, iter_max=2000):\n",
    "        # init step\n",
    "        b = self.x_max\n",
    "        a = self.x_min\n",
    "        n = max( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "        m = min( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "        #self.recordmn.append([m, n])\n",
    "        # search\n",
    "        iteration = 1\n",
    "        min_index_old = 100000\n",
    "        while(iteration<=iter_max):\n",
    "            if( self.function(m) < self.function(n)):\n",
    "                min_index = m\n",
    "                b = n\n",
    "            elif( self.function(m) > self.function(n)):\n",
    "                min_index = n \n",
    "                a = m\n",
    "            else:\n",
    "                min_index = (m+n)/2.0\n",
    "                a = m\n",
    "                b = n\n",
    "            #if(self.function(min_index)>self.function((a+b)/2.0)):\n",
    "            min_index = (a+b)/2.0\n",
    "            self.recordmin.append([iteration, self.function(min_index)])\n",
    "            self.recordfx.append([min_index, self.function(min_index)])\n",
    "\n",
    "            n = max( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "            m = min( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "            self.recordmn.append([a, b])\n",
    "\n",
    "            if(abs(min_index - min_index_old)<=self.error):\n",
    "                #print(\"The accuracy has reached \"+str(self.error))\n",
    "                print('Iteration = '+str(iteration))\n",
    "                break\n",
    "\n",
    "            min_index_old = min_index\n",
    "            iteration += 1\n",
    "\n",
    "        return min_index, self.function(min_index)\n",
    "\n",
    "    def output(self, flag_fx=1,flag_converage = 1, flag_mn = 1):\n",
    "        if(flag_fx == 1):\n",
    "            with open(\"./outdata/1_One-Dimension_Line_Search/GoldenSection_fx.dat\", 'w') as f:\n",
    "                f.write(\"Variables = x, f(x) \\n\")\n",
    "                f.write(\"zone \\n\")\n",
    "                x = np.linspace(self.x_min,self.x_max,1000)\n",
    "                for i in x:\n",
    "                    f.write(str(i)+' '+str(self.function(i))+ \"\\n\")\n",
    "                f.write(\"zone \\n\")\n",
    "                for j in self.recordfx:\n",
    "                    f.write(str(j[0])+' '+str(j[1])+ \"\\n\")\n",
    "\n",
    "        if(flag_converage == 1):\n",
    "            with open(\"./outdata/1_One-Dimension_Line_Search/GoldenSection_converage.dat\", 'w') as f:\n",
    "                f.write(\"Variables = x, f(x) \\n\")\n",
    "                f.write(\"zone \\n\")\n",
    "                for j in range(len(self.recordmin)):\n",
    "                    f.write(str(j)+' '+str(self.recordmin[j][1])+ \"\\n\")\n",
    "\n",
    "        if(flag_mn == 1):\n",
    "            with open(\"./outdata/1_One-Dimension_Line_Search/GoldenSection_x1x2.dat\", 'w') as f:\n",
    "                f.write(\"Variables = x, f(x) \\n\")\n",
    "                i = 0.01\n",
    "                for j in self.recordmn:\n",
    "                    f.write(\"zone \\n\")\n",
    "                    f.write(str(j[0])+' '+str(i)+ \"\\n\")\n",
    "                    f.write(str(j[1])+' '+str(i)+ \"\\n\")\n",
    "                    i = i+0.0001\n",
    "                    \n",
    "\n",
    "Golden = GoldenSectionMethod(function=Cal_Cd)\n",
    "A_min, Cd_min = Golden.Search()\n",
    "Golden.output()\n",
    "\n",
    "for i in range(10):\n",
    "    Golden = GoldenSectionMethod(function=Cal_Cd, x_min=1.0, x_max=float(10+i*10))\n",
    "    A_min, Cd_min = Golden.Search()\n",
    "    print(A_min,Cd_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A line search that satisfies the strong Wolfe conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一维搜索问题，定义：\n",
    "$$\n",
    "\\phi (A_{k} + \\alpha) = C_{d} = k C_{f} \\frac{S_{w e t}}{S}+\\frac{C_{L}^{2}}{\\pi (A_{k} + \\alpha) e}\n",
    "$$\n",
    "其中，\n",
    "$$\n",
    "C_{f} = \\frac{0.074}{R e^{0.2}} \\\\\n",
    "R e = \\frac{\\rho V c }{\\mu} = \\frac{\\rho V \\sqrt{S} }{\\mu} \\frac{1}{\\sqrt{A_{k} + \\alpha}}\n",
    "$$\n",
    "则函数$\\phi$的一阶导数为：\n",
    "$$\n",
    "\\phi^{'} (\\alpha) = \\frac{\\mathrm{d} C_{d}}{\\mathrm{d} \\alpha} \n",
    "= k \\frac{S_{w e t}}{S} \\frac{\\mathrm{d} C_{f}}{\\mathrm{d} \\alpha} - \\frac{C_{L}^{2}}{\\pi (A_{k} + \\alpha)^{2} e}\n",
    "$$\n",
    "\n",
    "其中，\n",
    "$$\n",
    "\\frac{\\mathrm{d} C_{f}}{\\mathrm{d} \\alpha} = - \\frac{0.2 \\times 0.074}{R e^{1.2}} \\frac{\\mathrm{d} Re}{\\mathrm{d} \\alpha}\n",
    "= \\frac{0.2 \\times 0.074}{R e^{1.2}} \\frac{ \\rho V \\sqrt{S}}{\\mu} (0.5*\\frac{1}{(A_{k} + \\alpha)^{1.5}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "28.39424765110016 0.01156068898716672\n",
      "16\n",
      "28.39424765110016 0.01156068898716672\n",
      "15\n",
      "28.39424765110016 0.01156068898716672\n",
      "14\n",
      "28.39424765110016 0.01156068898716672\n",
      "15\n",
      "28.39424765110016 0.01156068898716672\n",
      "16\n",
      "28.39424765110016 0.01156068898716672\n",
      "16\n",
      "28.39424765110016 0.01156068898716672\n",
      "16\n",
      "28.39424765110016 0.01156068898716672\n",
      "16\n",
      "28.39424765110016 0.01156068898716672\n",
      "15\n",
      "28.39424765110016 0.01156068898716672\n"
     ]
    }
   ],
   "source": [
    "def grad_Cd(A, k=1.2, S=11.8, S_ratio=2.05, Cl=0.3, e=0.96, rho=1.23, V=35.0, mu=17.8e-6):\n",
    "    \"\"\"Calculate the gradient of Cd as the function of A\"\"\"\n",
    "    b = np.sqrt(A*S)\n",
    "    c = S/b\n",
    "    Re = Cal_Re(c)\n",
    "    phi1 = k*S_ratio*(0.2*0.074)/(Re**1.2)*rho*V*np.sqrt(S)/mu*0.5*(A**-1.5)\n",
    "    phi2 = Cl**2/(np.pi * A**2 * e)\n",
    "\n",
    "    return phi1 - phi2\n",
    "\n",
    "class WolfeConditionsSearch():\n",
    "    \"\"\"A line search that satisfies the strong Wolfe conditions.\"\"\"\n",
    "    def __init__(self, xfunction, p, x_init=1.0, x_min=1.0, x_max=200.0, mu1=1e-4, mu2=0.9):\n",
    "        self.xfunction = xfunction\n",
    "        self.x_max = x_max\n",
    "        self.x_min = x_min\n",
    "        self.mu1 = mu1\n",
    "        self.mu2 = mu2\n",
    "        self.x_init = x_init\n",
    "        self.p = p\n",
    "        if( x_init<x_min or x_init>x_max ):\n",
    "            print(\"the start point is beyond the boundry\")\n",
    "            return None\n",
    "    \n",
    "    def function(self, a):\n",
    "        return self.xfunction(self.x_init + a * self.p)\n",
    "\n",
    "    def gfunction(self, a, h=0.0001):\n",
    "        return (self.function(a+h)-self.function(a-h))/(2*h)\n",
    "\n",
    "    def lineSearch(self, a_step = 1 , iter_max=2000):\n",
    "        # Search the space of a\n",
    "        a_best = 0\n",
    "        a0 = 0\n",
    "        a = a0 + a_step\n",
    "        find = False\n",
    "        iteration = 1    \n",
    "        while(iteration<iter_max):\n",
    "            if(self.x_init + a * self.p < self.x_min ):\n",
    "                a_min = a - a_step\n",
    "                a_max = self.x_init - self.x_min\n",
    "                break\n",
    "            elif(self.x_init + a * self.p > self.x_max):\n",
    "                a_min = a - a_step\n",
    "                a_max = self.x_max - self.x_init\n",
    "                break\n",
    "            if(self.function(a) > self.function(a0) + self.mu1*a*self.gfunction(a0)):\n",
    "                a_min = a - a_step\n",
    "                a_max = a \n",
    "                break\n",
    "            if(abs(self.gfunction(a)) < abs(self.mu2*self.gfunction(a0)) ):\n",
    "                a_best = a\n",
    "                find = True \n",
    "                break\n",
    "            if(self.gfunction(a)*self.gfunction(a0)<0):\n",
    "                a_min = a - a_step\n",
    "                a_max = a \n",
    "                break\n",
    "            a += a_step\n",
    "            iteration += 1\n",
    "        if(iteration>=iter_max):\n",
    "            print(\"There is no minimum point\")\n",
    "            return 404\n",
    "\n",
    "        if(find):\n",
    "            return self.x_init + a_best * self.p\n",
    "            \n",
    "        # reduce the space of a\n",
    "        iteration = 1\n",
    "        while(iteration<iter_max):  \n",
    "            a = (a_min + a_max) / 2.0\n",
    "            if(self.x_init + a * self.p < self.x_min or self.x_init + a * self.p > self.x_max):\n",
    "                print(\"the step of a is too large\")\n",
    "                return 404\n",
    "            if(self.function(a) > self.function(a0)+self.mu1*a*self.gfunction(a0)):\n",
    "                a_max = a \n",
    "                continue\n",
    "            if(abs(self.gfunction(a)) < abs(self.mu2*self.gfunction(a0))):\n",
    "                a_best = a\n",
    "                find = True \n",
    "                break\n",
    "            if(self.gfunction(a)*(a_max - a_min)>0):\n",
    "                a_max = a \n",
    "            elif(self.gfunction(a)*(a_max - a_min)<0):\n",
    "                a_min = a\n",
    "            iteration += 1\n",
    "        \n",
    "        if(find):\n",
    "            return self.x_init + a_best * self.p\n",
    "        else:\n",
    "            print(\"The iteration has reach the maximum number\")\n",
    "            return 404\n",
    "\n",
    "\n",
    "with open(\"./outdata/1_One-Dimension_Line_Search/WolfeCondition_converage.dat\", 'w') as f:\n",
    "    f.write(\"Variables = iteration, f(x) \\n\")\n",
    "    for i in range(10):\n",
    "        f.write(\"zone \\n\")\n",
    "        init_x = 1.0 + i*10.0\n",
    "        iteration = 1\n",
    "        error = 10000\n",
    "        f.write(str(iteration)+' '+str(Cal_Cd(init_x))+ \"\\n\")\n",
    "        while( error > 1e-6):\n",
    "            p =  - grad_Cd(init_x)/abs(grad_Cd(init_x))\n",
    "            wolfe = WolfeConditionsSearch(Cal_Cd, p, x_init=init_x)\n",
    "            a = wolfe.lineSearch(a_step=10, iter_max=1000)\n",
    "            if(a == 404):\n",
    "                break\n",
    "            #error = abs(Cal_Cd(init_x+a)-Cal_Cd(init_x))\n",
    "            error = abs(a - init_x)\n",
    "            init_x = a \n",
    "            iteration += 1\n",
    "            f.write(str(iteration)+' '+str(Cal_Cd(a))+ \"\\n\")\n",
    "        print(iteration)\n",
    "        print(init_x, Cal_Cd(init_x))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5602b0d5bcecdb19112768373585ebe9d46bec45992eaecef9a7dbb3e73a726c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
