{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimension Line Search 一维线搜索\n",
    "\n",
    "## 问题描述\n",
    "\n",
    "Consider a rectangular wing of span $b$ and chord $c$. Its planform area is thus $ S=b c $ and its aspect ratio is $ A = b^{2} / S $. The drag of this wing can be approximated as,\n",
    "$$\n",
    "C_{D}=k C_{f} \\frac{S_{w e t}}{S}+\\frac{C_{L}^{2}}{\\pi A e}\n",
    "$$\n",
    "The first term corresponds to the parasite drag. $ C_{f} $ is the skin friction coefficient, which for a fully turbulent boundary layer can be approximated as,\n",
    "$$\n",
    "C_{f}=\\frac{0.074}{R e^{0.2}}\n",
    "$$\n",
    "Here, the Reynolds number $ (R e=\\rho V c / \\mu) $ is based on the wing chord. $ k $ is the form factor, which accounts for the effects of pressure drag.\n",
    "\n",
    "The second term in Equation (1) is the induced drag, where $ e $ is the Oswald efficiency factor. The lift coefficient $ C_{L} $ and the wing planform area $ S $ are to be kept constant. The values for all the constants are listed in Table 1. \n",
    "\n",
    "1. Write the total drag coefficient as a function of $ A $.\n",
    "2. Minimize $ C_{D} $ with respect to $ A $ using:   \n",
    "    (a) The golden section method  \n",
    "    (b) A line search method that satisfies sufficient decrease. (Bonus: A line search that satisfies the strong Wolfe conditions.)  \n",
    "    Converge the solutions to 6 significant digits.  \n",
    "3. Discuss the relative performance of these two methods. Try different starting points/intervals and compare convergence rates, number of iterations and any other metrics you find suitable.\n",
    "\n",
    "\\begin{array}{lrll}\n",
    "\\text { Quantity } & \\text { Value } & \\text { Units } & \\text { Description } \\\\\n",
    "\\hline \\rho & 1.23 & \\mathrm{~kg} / \\mathrm{m}^{3} & \\text { density of air } \\\\\n",
    "\\mu & 17.8 \\times 10^{-6} & \\mathrm{~kg} /(\\mathrm{m} \\mathrm{sec}) & \\text { viscosity of air } \\\\\n",
    "V & 35 & \\mathrm{~m} / \\mathrm{s} & \\text { airspeed } \\\\\n",
    "S & 11.8 & \\mathrm{~m}^{2} & \\text { planform area } \\\\\n",
    "S_{\\text {wet }} & 2.05 S & \\mathrm{~m}^{2} & \\text { wing wetted area } \\\\\n",
    "k & 1.2 & & \\text { form factor } \\\\\n",
    "C_{L} & 0.3 & & \\text { lift coefficient } \\\\\n",
    "e & 0.96 & & \\text { Oswald efficiency factor } \\\\\n",
    "\\hline\n",
    "\\end{array}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Cal_Re(c, rho=1.23, V=35.0, mu=17.8e-6):\n",
    "    \"\"\"Calculate Reynolds number.\"\"\"\n",
    "    return rho*V*c/mu\n",
    "\n",
    "def Cal_Cf(Re):\n",
    "    \"\"\"Calculate the skin friction coefficient\"\"\"\n",
    "    return 0.074/(Re**0.2)\n",
    "\n",
    "def Cal_Cd(A, k=1.2, S=11.8, S_ratio=2.05, Cl=0.3, e=0.96):\n",
    "    \"\"\"Calculate the total drag coefficient as the function of A\"\"\"\n",
    "    b = np.sqrt(A*S)\n",
    "    c = S/b\n",
    "    Re = Cal_Re(c)\n",
    "    Cf = Cal_Cf(Re)\n",
    "    return k*Cf*S_ratio+Cl**2/(np.pi*A*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Golden Section Method 黄金切割法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy has reached 1e-06\n",
      "Iteration = 22\n",
      "28.394733234617927 0.011560688987335527\n"
     ]
    }
   ],
   "source": [
    "class GoldenSectionMethod():\n",
    "    \"\"\"Golden Section Method\"\"\"\n",
    "    def __init__(self, function, x_min=1.0, x_max=100.0, tau=0.618, error = 1e-6):\n",
    "        self.x_max = x_max\n",
    "        self.x_min = x_min\n",
    "        self.function = function\n",
    "        self.tau = tau\n",
    "        self.error = error\n",
    "\n",
    "    def Search(self, iter_max=2000):\n",
    "        # init step\n",
    "        b = self.x_max\n",
    "        a = self.x_min\n",
    "        n = max( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "        m = min( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "        \n",
    "        # search\n",
    "        iteration = 1\n",
    "        min_index_old = 100000\n",
    "        while(iteration<=iter_max):\n",
    "            if( self.function(m) < self.function(n)):\n",
    "                min_index = m\n",
    "                b = n\n",
    "            elif( self.function(m) > self.function(n)):\n",
    "                min_index = n \n",
    "                a = m\n",
    "            else:\n",
    "                min_index = (m+n)/2.0\n",
    "                a = m\n",
    "                b = n\n",
    "            n = max( a + (b-a)*self.tau, b - (b-a)*self.tau )\n",
    "            m = min( a + (b-a)*self.tau, b - (b-a)*self.tau ) \n",
    "\n",
    "            if(abs(min_index - min_index_old)<=self.error):\n",
    "                print(\"The accuracy has reached \"+str(self.error))\n",
    "                print('Iteration = '+str(iteration))\n",
    "                break\n",
    "\n",
    "            min_index_old = min_index\n",
    "            iteration += 1\n",
    "\n",
    "        return min_index, self.function(min_index)\n",
    "\n",
    "Golden = GoldenSectionMethod(function=Cal_Cd)\n",
    "A_min, Cd_min = Golden.Search()\n",
    "print(A_min,Cd_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A line search that satisfies the strong Wolfe conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一维搜索问题，定义：\n",
    "$$\n",
    "\\phi (A_{k} + \\alpha) = C_{d} = k C_{f} \\frac{S_{w e t}}{S}+\\frac{C_{L}^{2}}{\\pi (A_{k} + \\alpha) e}\n",
    "$$\n",
    "其中，\n",
    "$$\n",
    "C_{f} = \\frac{0.074}{R e^{0.2}} \\\\\n",
    "R e = \\frac{\\rho V c }{\\mu} = \\frac{\\rho V \\sqrt{S} }{\\mu} \\frac{1}{\\sqrt{A_{k} + \\alpha}}\n",
    "$$\n",
    "则函数$\\phi$的一阶导数为：\n",
    "$$\n",
    "\\phi^{'} (\\alpha) = \\frac{\\mathrm{d} C_{d}}{\\mathrm{d} \\alpha} \n",
    "= k \\frac{S_{w e t}}{S} \\frac{\\mathrm{d} C_{f}}{\\mathrm{d} \\alpha} - \\frac{C_{L}^{2}}{\\pi (A_{k} + \\alpha)^{2} e}\n",
    "$$\n",
    "\n",
    "其中，\n",
    "$$\n",
    "\\frac{\\mathrm{d} C_{f}}{\\mathrm{d} \\alpha} = - \\frac{0.2 \\times 0.074}{R e^{1.2}} \\frac{\\mathrm{d} Re}{\\mathrm{d} \\alpha}\n",
    "= \\frac{0.2 \\times 0.074}{R e^{1.2}} \\frac{ \\rho V \\sqrt{S}}{\\mu} (0.5*\\frac{1}{(A_{k} + \\alpha)^{1.5}})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.394247627258302 0.011560688987166721\n"
     ]
    }
   ],
   "source": [
    "def grad_Cd(A, k=1.2, S=11.8, S_ratio=2.05, Cl=0.3, e=0.96, rho=1.23, V=35.0, mu=17.8e-6):\n",
    "    \"\"\"Calculate the gradient of Cd as the function of A\"\"\"\n",
    "    b = np.sqrt(A*S)\n",
    "    c = S/b\n",
    "    Re = Cal_Re(c)\n",
    "    phi1 = k*S_ratio*(0.2*0.074)/(Re**1.2)*rho*V*np.sqrt(S)/mu*0.5*(A**-1.5)\n",
    "    phi2 = Cl**2/(np.pi * A**2 * e)\n",
    "\n",
    "    return phi1 - phi2\n",
    "\n",
    "class WolfeConditionsSearch():\n",
    "    \"\"\"A line search that satisfies the strong Wolfe conditions.\"\"\"\n",
    "    def __init__(self, function, grad_function, x_min=1.0, x_max=100.0, mu1=1e-4, mu2=0.9):\n",
    "        self.x_max = x_max\n",
    "        self.x_min = x_min\n",
    "        self.function = function\n",
    "        self.grad_function = grad_function\n",
    "        self.mu1 = mu1\n",
    "        self.mu2 = mu2\n",
    "    \n",
    "    def lineSearch(self, init_x=float('inf'), a_step = 1 , iter_max=2000):\n",
    "        if(init_x == float('inf')):\n",
    "            #init_x = np.random.uniform(self.x_min, self.x_max)\n",
    "            init_x = self.x_min\n",
    "        #print(\"The start points is \"+str(init_x))\n",
    "        \n",
    "        # Search the space of a\n",
    "        a_best = 0\n",
    "        a1 = 0\n",
    "        a2 = a1 + a_step\n",
    "        find = False    \n",
    "        while(True):\n",
    "            # wheather the (x+a) has reached the max of x\n",
    "            if((init_x+a2)>self.x_max):\n",
    "                a_min = a1\n",
    "                a_max = self.x_max\n",
    "                break\n",
    "            if(self.function(init_x + a2) > self.function(init_x) + self.mu1*a2*self.grad_function(init_x)):\n",
    "                a_min = a1\n",
    "                a_max = a2 \n",
    "                break\n",
    "            if(abs(self.grad_function(init_x + a2)) < -self.mu2*self.grad_function(init_x) and self.grad_function(init_x + a2)<0):\n",
    "                a_best = a2\n",
    "                find = True \n",
    "                break\n",
    "            if(self.grad_function(init_x + a2)>0):\n",
    "                a_min = a1\n",
    "                a_max = a2 \n",
    "                break\n",
    "            a1 = a2\n",
    "            a2 += a_step\n",
    "\n",
    "        if(find):\n",
    "            return a_best\n",
    "\n",
    "        if(a_max == self.x_max):\n",
    "            #print(\"There is no min points 101\")\n",
    "            return 101\n",
    "            \n",
    "        # decrease the space of a\n",
    "        iteration = 1\n",
    "        while(iteration<iter_max):  \n",
    "            a1 = a_min\n",
    "            a2 = (a_min + a_max) / 2.0\n",
    "            if(self.function(init_x + a2) > self.function(init_x)+self.mu1*a2*self.grad_function(init_x)):\n",
    "                a_max = a2 \n",
    "                continue\n",
    "            if(abs(self.grad_function(init_x + a2)) < abs(self.mu2*self.grad_function(init_x)) and self.grad_function(init_x + a2)<0):\n",
    "                a_best = a2\n",
    "                find = True \n",
    "                break\n",
    "            if(self.grad_function(init_x + a2)*(a_max - a_min)>0):\n",
    "                a_max = a2 \n",
    "            elif(self.grad_function(init_x + a2)*(a_max - a_min)<0):\n",
    "                a_min = a2\n",
    "            iteration += 1\n",
    "        \n",
    "        if(find):\n",
    "            return a_best\n",
    "        else:\n",
    "            #print(\"There is no min point 202\")\n",
    "            return 202\n",
    "\n",
    "init_x = 0.1\n",
    "i = 1\n",
    "error = 10000\n",
    "while( error > 1e-6 and i<1000):\n",
    "    wolfe = WolfeConditionsSearch(Cal_Cd, grad_Cd)\n",
    "    a = wolfe.lineSearch(init_x=init_x,a_step=1, iter_max=1000)\n",
    "    if(a == 101 or a == 202):\n",
    "        break\n",
    "    #error = abs(Cal_Cd(init_x+a)-Cal_Cd(init_x))\n",
    "    error = a\n",
    "    init_x += a \n",
    "    i +=1\n",
    "print(init_x, Cal_Cd(init_x))       "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
